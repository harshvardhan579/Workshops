{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for Titanic: Planning\n",
    "\n",
    "Plan:\n",
    "- use sklearn\n",
    "    - use built in sklearn functionality for everything possible, including preprocessing\n",
    "- use few features:\n",
    "    - sex\n",
    "    - age\n",
    "    - pclass?\n",
    "    - fare?\n",
    "- start by exploring all data\n",
    "    - df.head()\n",
    "    - choose relevant features and explain\n",
    "- preprocess data\n",
    "    - fill in missing values\n",
    "    - one-hot encode categorical\n",
    "    - normalize numerical\n",
    "        - don't just use sklearn's normalize -- write own\n",
    "- use cross validation to find best number of neighbors?\n",
    "    - outside scope of workshop?\n",
    "    - won't work?\n",
    "        - try it on own first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset and visualize first few entries\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the data! Let's select relevant features. \n",
    "\n",
    "Which features do you think will be good predictors of survival?\n",
    "\n",
    "Let's consider the phrase 'women and children first'. Let's also consider location in the ship, determined by passenger class. We'll choose:\n",
    "- Pclass\n",
    "- Sex\n",
    "- Age\n",
    "\n",
    "We also need to save the 'Survived' column of the data. This is what we are trying to predict! These are our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features:\n",
      " [[3 'male' 22.0]\n",
      " [1 'female' 38.0]\n",
      " [3 'female' 26.0]\n",
      " [1 'female' 35.0]\n",
      " [3 'male' 35.0]]\n",
      "\n",
      "Labels:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# choose relevant features\n",
    "pclass = data.Pclass.values\n",
    "sex = data.Sex.values\n",
    "age = data.Age.values\n",
    "\n",
    "# save labels\n",
    "y = data.Survived.values\n",
    "\n",
    "# save number of data points\n",
    "m = y.size\n",
    "\n",
    "print('\\nFeatures:\\n', np.array([pclass[:5], sex[:5], age[:5]]).T)\n",
    "print('\\nLabels:\\n', y[:5].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using k-nearest neighbors, we need to make sure the data is in the right form. Is there a problem with our current setup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem! Well, multiple problems, actually. \n",
    "\n",
    "First off, Sex is not a number. K-nearest neighbors can only learn from numerical features. Let's fix that by one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode Sex feature\n",
    "sex = np.asarray([1 if sex[i] == 'male' else 0 for i in range(m)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now our data is all numerical, and k-nearest neighbors can learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there's still a problem...\n",
    "\n",
    "Look at the range of values for each feature. Are they all on the same scale?\n",
    "\n",
    "They're not! Age has a much larger range of values than either sex or class.\n",
    "\n",
    "This is a problem! Age differences will be considered much more significant than differences in sex or class. This does not make sense for our problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by scaling and shifting our feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! Looks like something is strange..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.  ,  38.  ,  26.  ,  35.  ,  35.  ,    nan,  54.  ,   2.  ,\n",
       "        27.  ,  14.  ,   4.  ,  58.  ,  20.  ,  39.  ,  14.  ,  55.  ,\n",
       "         2.  ,    nan,  31.  ,    nan,  35.  ,  34.  ,  15.  ,  28.  ,\n",
       "         8.  ,  38.  ,    nan,  19.  ,    nan,    nan,  40.  ,    nan,\n",
       "          nan,  66.  ,  28.  ,  42.  ,    nan,  21.  ,  18.  ,  14.  ,\n",
       "        40.  ,  27.  ,    nan,   3.  ,  19.  ,    nan,    nan,    nan,\n",
       "          nan,  18.  ,   7.  ,  21.  ,  49.  ,  29.  ,  65.  ,    nan,\n",
       "        21.  ,  28.5 ,   5.  ,  11.  ,  22.  ,  38.  ,  45.  ,   4.  ,\n",
       "          nan,    nan,  29.  ,  19.  ,  17.  ,  26.  ,  32.  ,  16.  ,\n",
       "        21.  ,  26.  ,  32.  ,  25.  ,    nan,    nan,   0.83,  30.  ,\n",
       "        22.  ,  29.  ,    nan,  28.  ,  17.  ,  33.  ,  16.  ,    nan,\n",
       "        23.  ,  24.  ,  29.  ,  20.  ,  46.  ,  26.  ,  59.  ,    nan,\n",
       "        71.  ,  23.  ,  34.  ,  34.  ,  28.  ,    nan,  21.  ,  33.  ,\n",
       "        37.  ,  28.  ,  21.  ,    nan,  38.  ,    nan,  47.  ,  14.5 ,\n",
       "        22.  ,  20.  ,  17.  ,  21.  ,  70.5 ,  29.  ,  24.  ,   2.  ,\n",
       "        21.  ,    nan,  32.5 ,  32.5 ,  54.  ,  12.  ,    nan,  24.  ,\n",
       "          nan,  45.  ,  33.  ,  20.  ,  47.  ,  29.  ,  25.  ,  23.  ,\n",
       "        19.  ,  37.  ,  16.  ,  24.  ,    nan,  22.  ,  24.  ,  19.  ,\n",
       "        18.  ,  19.  ,  27.  ,   9.  ,  36.5 ,  42.  ,  51.  ,  22.  ,\n",
       "        55.5 ,  40.5 ,    nan,  51.  ,  16.  ,  30.  ,    nan,    nan,\n",
       "        44.  ,  40.  ,  26.  ,  17.  ,   1.  ,   9.  ,    nan,  45.  ,\n",
       "          nan,  28.  ,  61.  ,   4.  ,   1.  ,  21.  ,  56.  ,  18.  ,\n",
       "          nan,  50.  ,  30.  ,  36.  ,    nan,    nan,   9.  ,   1.  ,\n",
       "         4.  ,    nan,    nan,  45.  ,  40.  ,  36.  ,  32.  ,  19.  ,\n",
       "        19.  ,   3.  ,  44.  ,  58.  ,    nan,  42.  ,    nan,  24.  ,\n",
       "        28.  ,    nan,  34.  ,  45.5 ,  18.  ,   2.  ,  32.  ,  26.  ,\n",
       "        16.  ,  40.  ,  24.  ,  35.  ,  22.  ,  30.  ,    nan,  31.  ,\n",
       "        27.  ,  42.  ,  32.  ,  30.  ,  16.  ,  27.  ,  51.  ,    nan,\n",
       "        38.  ,  22.  ,  19.  ,  20.5 ,  18.  ,    nan,  35.  ,  29.  ,\n",
       "        59.  ,   5.  ,  24.  ,    nan,  44.  ,   8.  ,  19.  ,  33.  ,\n",
       "          nan,    nan,  29.  ,  22.  ,  30.  ,  44.  ,  25.  ,  24.  ,\n",
       "        37.  ,  54.  ,    nan,  29.  ,  62.  ,  30.  ,  41.  ,  29.  ,\n",
       "          nan,  30.  ,  35.  ,  50.  ,    nan,   3.  ,  52.  ,  40.  ,\n",
       "          nan,  36.  ,  16.  ,  25.  ,  58.  ,  35.  ,    nan,  25.  ,\n",
       "        41.  ,  37.  ,    nan,  63.  ,  45.  ,    nan,   7.  ,  35.  ,\n",
       "        65.  ,  28.  ,  16.  ,  19.  ,    nan,  33.  ,  30.  ,  22.  ,\n",
       "        42.  ,  22.  ,  26.  ,  19.  ,  36.  ,  24.  ,  24.  ,    nan,\n",
       "        23.5 ,   2.  ,    nan,  50.  ,    nan,    nan,  19.  ,    nan,\n",
       "          nan,   0.92,    nan,  17.  ,  30.  ,  30.  ,  24.  ,  18.  ,\n",
       "        26.  ,  28.  ,  43.  ,  26.  ,  24.  ,  54.  ,  31.  ,  40.  ,\n",
       "        22.  ,  27.  ,  30.  ,  22.  ,    nan,  36.  ,  61.  ,  36.  ,\n",
       "        31.  ,  16.  ,    nan,  45.5 ,  38.  ,  16.  ,    nan,    nan,\n",
       "        29.  ,  41.  ,  45.  ,  45.  ,   2.  ,  24.  ,  28.  ,  25.  ,\n",
       "        36.  ,  24.  ,  40.  ,    nan,   3.  ,  42.  ,  23.  ,    nan,\n",
       "        15.  ,  25.  ,    nan,  28.  ,  22.  ,  38.  ,    nan,    nan,\n",
       "        40.  ,  29.  ,  45.  ,  35.  ,    nan,  30.  ,  60.  ,    nan,\n",
       "          nan,  24.  ,  25.  ,  18.  ,  19.  ,  22.  ,   3.  ,    nan,\n",
       "        22.  ,  27.  ,  20.  ,  19.  ,  42.  ,   1.  ,  32.  ,  35.  ,\n",
       "          nan,  18.  ,   1.  ,  36.  ,    nan,  17.  ,  36.  ,  21.  ,\n",
       "        28.  ,  23.  ,  24.  ,  22.  ,  31.  ,  46.  ,  23.  ,  28.  ,\n",
       "        39.  ,  26.  ,  21.  ,  28.  ,  20.  ,  34.  ,  51.  ,   3.  ,\n",
       "        21.  ,    nan,    nan,    nan,  33.  ,    nan,  44.  ,    nan,\n",
       "        34.  ,  18.  ,  30.  ,  10.  ,    nan,  21.  ,  29.  ,  28.  ,\n",
       "        18.  ,    nan,  28.  ,  19.  ,    nan,  32.  ,  28.  ,    nan,\n",
       "        42.  ,  17.  ,  50.  ,  14.  ,  21.  ,  24.  ,  64.  ,  31.  ,\n",
       "        45.  ,  20.  ,  25.  ,  28.  ,    nan,   4.  ,  13.  ,  34.  ,\n",
       "         5.  ,  52.  ,  36.  ,    nan,  30.  ,  49.  ,    nan,  29.  ,\n",
       "        65.  ,    nan,  50.  ,    nan,  48.  ,  34.  ,  47.  ,  48.  ,\n",
       "          nan,  38.  ,    nan,  56.  ,    nan,   0.75,    nan,  38.  ,\n",
       "        33.  ,  23.  ,  22.  ,    nan,  34.  ,  29.  ,  22.  ,   2.  ,\n",
       "         9.  ,    nan,  50.  ,  63.  ,  25.  ,    nan,  35.  ,  58.  ,\n",
       "        30.  ,   9.  ,    nan,  21.  ,  55.  ,  71.  ,  21.  ,    nan,\n",
       "        54.  ,    nan,  25.  ,  24.  ,  17.  ,  21.  ,    nan,  37.  ,\n",
       "        16.  ,  18.  ,  33.  ,    nan,  28.  ,  26.  ,  29.  ,    nan,\n",
       "        36.  ,  54.  ,  24.  ,  47.  ,  34.  ,    nan,  36.  ,  32.  ,\n",
       "        30.  ,  22.  ,    nan,  44.  ,    nan,  40.5 ,  50.  ,    nan,\n",
       "        39.  ,  23.  ,   2.  ,    nan,  17.  ,    nan,  30.  ,   7.  ,\n",
       "        45.  ,  30.  ,    nan,  22.  ,  36.  ,   9.  ,  11.  ,  32.  ,\n",
       "        50.  ,  64.  ,  19.  ,    nan,  33.  ,   8.  ,  17.  ,  27.  ,\n",
       "          nan,  22.  ,  22.  ,  62.  ,  48.  ,    nan,  39.  ,  36.  ,\n",
       "          nan,  40.  ,  28.  ,    nan,    nan,  24.  ,  19.  ,  29.  ,\n",
       "          nan,  32.  ,  62.  ,  53.  ,  36.  ,    nan,  16.  ,  19.  ,\n",
       "        34.  ,  39.  ,    nan,  32.  ,  25.  ,  39.  ,  54.  ,  36.  ,\n",
       "          nan,  18.  ,  47.  ,  60.  ,  22.  ,    nan,  35.  ,  52.  ,\n",
       "        47.  ,    nan,  37.  ,  36.  ,    nan,  49.  ,    nan,  49.  ,\n",
       "        24.  ,    nan,    nan,  44.  ,  35.  ,  36.  ,  30.  ,  27.  ,\n",
       "        22.  ,  40.  ,  39.  ,    nan,    nan,    nan,  35.  ,  24.  ,\n",
       "        34.  ,  26.  ,   4.  ,  26.  ,  27.  ,  42.  ,  20.  ,  21.  ,\n",
       "        21.  ,  61.  ,  57.  ,  21.  ,  26.  ,    nan,  80.  ,  51.  ,\n",
       "        32.  ,    nan,   9.  ,  28.  ,  32.  ,  31.  ,  41.  ,    nan,\n",
       "        20.  ,  24.  ,   2.  ,    nan,   0.75,  48.  ,  19.  ,  56.  ,\n",
       "          nan,  23.  ,    nan,  18.  ,  21.  ,    nan,  18.  ,  24.  ,\n",
       "          nan,  32.  ,  23.  ,  58.  ,  50.  ,  40.  ,  47.  ,  36.  ,\n",
       "        20.  ,  32.  ,  25.  ,    nan,  43.  ,    nan,  40.  ,  31.  ,\n",
       "        70.  ,  31.  ,    nan,  18.  ,  24.5 ,  18.  ,  43.  ,  36.  ,\n",
       "          nan,  27.  ,  20.  ,  14.  ,  60.  ,  25.  ,  14.  ,  19.  ,\n",
       "        18.  ,  15.  ,  31.  ,   4.  ,    nan,  25.  ,  60.  ,  52.  ,\n",
       "        44.  ,    nan,  49.  ,  42.  ,  18.  ,  35.  ,  18.  ,  25.  ,\n",
       "        26.  ,  39.  ,  45.  ,  42.  ,  22.  ,    nan,  24.  ,    nan,\n",
       "        48.  ,  29.  ,  52.  ,  19.  ,  38.  ,  27.  ,    nan,  33.  ,\n",
       "         6.  ,  17.  ,  34.  ,  50.  ,  27.  ,  20.  ,  30.  ,    nan,\n",
       "        25.  ,  25.  ,  29.  ,  11.  ,    nan,  23.  ,  23.  ,  28.5 ,\n",
       "        48.  ,  35.  ,    nan,    nan,    nan,  36.  ,  21.  ,  24.  ,\n",
       "        31.  ,  70.  ,  16.  ,  30.  ,  19.  ,  31.  ,   4.  ,   6.  ,\n",
       "        33.  ,  23.  ,  48.  ,   0.67,  28.  ,  18.  ,  34.  ,  33.  ,\n",
       "          nan,  41.  ,  20.  ,  36.  ,  16.  ,  51.  ,    nan,  30.5 ,\n",
       "          nan,  32.  ,  24.  ,  48.  ,  57.  ,    nan,  54.  ,  18.  ,\n",
       "          nan,   5.  ,    nan,  43.  ,  13.  ,  17.  ,  29.  ,    nan,\n",
       "        25.  ,  25.  ,  18.  ,   8.  ,   1.  ,  46.  ,    nan,  16.  ,\n",
       "          nan,    nan,  25.  ,  39.  ,  49.  ,  31.  ,  30.  ,  30.  ,\n",
       "        34.  ,  31.  ,  11.  ,   0.42,  27.  ,  31.  ,  39.  ,  18.  ,\n",
       "        39.  ,  33.  ,  26.  ,  39.  ,  35.  ,   6.  ,  30.5 ,    nan,\n",
       "        23.  ,  31.  ,  43.  ,  10.  ,  52.  ,  27.  ,  38.  ,  27.  ,\n",
       "         2.  ,    nan,    nan,   1.  ,    nan,  62.  ,  15.  ,   0.83,\n",
       "          nan,  23.  ,  18.  ,  39.  ,  21.  ,    nan,  32.  ,    nan,\n",
       "        20.  ,  16.  ,  30.  ,  34.5 ,  17.  ,  42.  ,    nan,  35.  ,\n",
       "        28.  ,    nan,   4.  ,  74.  ,   9.  ,  16.  ,  44.  ,  18.  ,\n",
       "        45.  ,  51.  ,  24.  ,    nan,  41.  ,  21.  ,  48.  ,    nan,\n",
       "        24.  ,  42.  ,  27.  ,  31.  ,    nan,   4.  ,  26.  ,  47.  ,\n",
       "        33.  ,  47.  ,  28.  ,  15.  ,  20.  ,  19.  ,    nan,  56.  ,\n",
       "        25.  ,  33.  ,  22.  ,  28.  ,  25.  ,  39.  ,  27.  ,  19.  ,\n",
       "          nan,  26.  ,  32.  ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some missing values in age. Let's fill them in with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in missing values in age\n",
    "num_valid = 0\n",
    "sum_age = 0\n",
    "\n",
    "for i in range(m):\n",
    "    # if element in age is not missing, note as valid\n",
    "    if not np.isnan(age[i]):\n",
    "        num_valid += 1\n",
    "        sum_age += age[i]\n",
    "\n",
    "# out of valid points, find mean\n",
    "mean_age = sum_age / num_valid\n",
    "        \n",
    "\n",
    "# shift and scale age to range 0 -> 1\n",
    "age -= np.mean(age) - 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
